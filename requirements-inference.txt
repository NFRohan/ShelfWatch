# ──────────────────────────────────────────────
# Inference-only dependencies (CPU ONNX — no PyTorch!)
# Slim image for m7i-flex / c7i deployment
# ──────────────────────────────────────────────

# ONNX inference (CPU only — ~15MB vs PyTorch's ~2GB)
onnxruntime>=1.17.0

# API
# Security Fixes
jaraco.context>=6.1.0
wheel>=0.46.2

# Core
fastapi>=0.115.0  # Pulls in starlette>=0.37.2 (fixes httpx issue)
uvicorn[standard]>=0.30.0
python-multipart>=0.0.18

# Image processing
Pillow>=10.0.0
numpy>=1.24.0

# Observability
prometheus-client>=0.20.0

# Performance
orjson>=3.9.0              # 10x faster JSON serialization than stdlib

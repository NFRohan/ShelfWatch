{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üè™ ShelfWatch ‚Äî YOLO11 Training (H100 Optimized)\n",
                "\n",
                "**Runtime:** GPU H100 (80GB VRAM)\n",
                "\n",
                "This notebook:\n",
                "1. Downloads SKU-110K from Roboflow\n",
                "2. Trains YOLO11l with H100-optimized settings\n",
                "3. Evaluates and visualizes results\n",
                "4. Logs to MLflow & exports ONNX\n",
                "5. Downloads best weights"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 0 ‚Äî Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q ultralytics roboflow mlflow\n",
                "\n",
                "import torch\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA:    {torch.version.cuda}\")\n",
                "print(f\"GPU:     {torch.cuda.get_device_name(0)}\")\n",
                "print(f\"VRAM:    {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1 ‚Äî Download Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install roboflow\n",
                "\n",
                "from roboflow import Roboflow\n",
                "rf = Roboflow(api_key=\"0tOITA1bMoPm91ApiWnt\")\n",
                "project = rf.workspace(\"boisheba\").project(\"sku-110k-bnaw9\")\n",
                "version = project.version(1)\n",
                "dataset = version.download(\"yolov11\")\n",
                "\n",
                "print(f\"\\n‚úÖ Dataset at: {dataset.location}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify structure & find data.yaml\n",
                "import os\n",
                "import glob\n",
                "\n",
                "# Find the data.yaml file\n",
                "yaml_candidates = glob.glob(os.path.join(dataset.location, \"**\", \"data.yaml\"), recursive=True)\n",
                "if not yaml_candidates:\n",
                "    yaml_candidates = glob.glob(os.path.join(dataset.location, \"**\", \"*.yaml\"), recursive=True)\n",
                "\n",
                "DATA_YAML = yaml_candidates[0] if yaml_candidates else os.path.join(dataset.location, \"data.yaml\")\n",
                "print(f\"Data YAML: {DATA_YAML}\\n\")\n",
                "\n",
                "with open(DATA_YAML) as f:\n",
                "    print(f.read())\n",
                "\n",
                "# Count images\n",
                "for split in [\"train\", \"valid\", \"test\"]:\n",
                "    imgs = glob.glob(os.path.join(dataset.location, split, \"images\", \"*\"))\n",
                "    print(f\"{split}: {len(imgs)} images\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2 ‚Äî Train YOLO11 (H100 Optimized)\n",
                "\n",
                "H100 optimizations applied:\n",
                "- **`batch=64`** ‚Äî 80GB VRAM handles this easily for YOLO11l @ 640px\n",
                "- **`amp=True`** ‚Äî automatic mixed precision (FP16/BF16), H100 excels at this\n",
                "- **`workers=12`** ‚Äî more data loader workers to keep GPU fed\n",
                "- **`imgsz=640`** ‚Äî standard; bump to 1280 if you want extra accuracy and have time\n",
                "- **`cos_lr=True`** ‚Äî cosine annealing LR for better convergence\n",
                "- **`patience=15`** ‚Äî early stopping to save time if plateaued"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from ultralytics import YOLO\n",
                "\n",
                "# ‚îÄ‚îÄ‚îÄ H100 Config ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
                "MODEL = \"yolo11l.pt\"       # Large ‚Äî sweet spot for H100\n",
                "EPOCHS = 50\n",
                "IMG_SIZE = 640\n",
                "BATCH_SIZE = 64            # H100 80GB ‚Üí 64 is comfortable for yolo11l\n",
                "WORKERS = 12               # keep GPU saturated\n",
                "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
                "\n",
                "model = YOLO(MODEL)\n",
                "\n",
                "results = model.train(\n",
                "    data=DATA_YAML,\n",
                "    epochs=EPOCHS,\n",
                "    imgsz=IMG_SIZE,\n",
                "    batch=BATCH_SIZE,\n",
                "    workers=WORKERS,\n",
                "    project=\"/kaggle/working/runs\",\n",
                "    name=\"shelfwatch\",\n",
                "    exist_ok=True,\n",
                "    \n",
                "    # ‚îÄ‚îÄ H100 Optimizations ‚îÄ‚îÄ\n",
                "    amp=True,               # mixed precision (FP16/BF16) ‚Äî huge speedup on H100\n",
                "    cos_lr=True,            # cosine LR schedule ‚Äî better convergence\n",
                "    \n",
                "    # ‚îÄ‚îÄ Training Quality ‚îÄ‚îÄ\n",
                "    patience=15,            # early stopping\n",
                "    save=True,\n",
                "    save_period=10,         # checkpoint every 10 epochs\n",
                "    plots=True,\n",
                "    verbose=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3 ‚Äî Evaluate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "best_model = YOLO(\"/kaggle/working/runs/shelfwatch/weights/best.pt\")\n",
                "metrics = best_model.val(data=DATA_YAML)\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"üìä EVALUATION RESULTS\")\n",
                "print(\"=\"*50)\n",
                "print(f\"  mAP50:     {metrics.box.map50:.4f}\")\n",
                "print(f\"  mAP50-95:  {metrics.box.map:.4f}\")\n",
                "print(f\"  Precision: {metrics.box.mp:.4f}\")\n",
                "print(f\"  Recall:    {metrics.box.mr:.4f}\")\n",
                "print(\"=\"*50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Show training curves\n",
                "from IPython.display import Image as IPImage, display\n",
                "\n",
                "plots_dir = \"/kaggle/working/runs/shelfwatch\"\n",
                "for plot_name in [\"results.png\", \"confusion_matrix.png\", \"val_batch0_pred.png\"]:\n",
                "    plot_path = os.path.join(plots_dir, plot_name)\n",
                "    if os.path.exists(plot_path):\n",
                "        print(f\"\\nüìà {plot_name}\")\n",
                "        display(IPImage(filename=plot_path, width=800))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4 ‚Äî Test Inference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import glob\n",
                "import time\n",
                "\n",
                "# Grab test images\n",
                "test_images = glob.glob(os.path.join(dataset.location, \"test\", \"images\", \"*\"))[:5]\n",
                "if not test_images:\n",
                "    test_images = glob.glob(os.path.join(dataset.location, \"valid\", \"images\", \"*\"))[:5]\n",
                "\n",
                "for img_path in test_images:\n",
                "    start = time.perf_counter()\n",
                "    results = best_model.predict(img_path, imgsz=640, conf=0.25, save=True,\n",
                "                                  project=\"/kaggle/working/predictions\", exist_ok=True)\n",
                "    latency = (time.perf_counter() - start) * 1000\n",
                "    \n",
                "    n = len(results[0].boxes)\n",
                "    print(f\"\\nüîç {os.path.basename(img_path)} ‚Äî {n} products detected ({latency:.0f}ms)\")\n",
                "    \n",
                "    pred_file = os.path.join(\"/kaggle/working/predictions/predict\", os.path.basename(img_path))\n",
                "    if os.path.exists(pred_file):\n",
                "        display(IPImage(filename=pred_file, width=800))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5 ‚Äî Log to MLflow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import mlflow\n",
                "\n",
                "mlflow.set_experiment(\"shelfwatch-training\")\n",
                "\n",
                "with mlflow.start_run(run_name=f\"yolo11l-ep{EPOCHS}-h100\"):\n",
                "    mlflow.log_params({\n",
                "        \"model\": MODEL,\n",
                "        \"epochs\": EPOCHS,\n",
                "        \"img_size\": IMG_SIZE,\n",
                "        \"batch_size\": BATCH_SIZE,\n",
                "        \"dataset\": \"SKU-110K\",\n",
                "        \"gpu\": \"H100\",\n",
                "        \"amp\": True,\n",
                "        \"cos_lr\": True,\n",
                "    })\n",
                "    \n",
                "    mlflow.log_metrics({\n",
                "        \"mAP50\": float(metrics.box.map50),\n",
                "        \"mAP50-95\": float(metrics.box.map),\n",
                "        \"precision\": float(metrics.box.mp),\n",
                "        \"recall\": float(metrics.box.mr),\n",
                "    })\n",
                "    \n",
                "    best_pt = \"/kaggle/working/runs/shelfwatch/weights/best.pt\"\n",
                "    if os.path.exists(best_pt):\n",
                "        mlflow.log_artifact(best_pt, artifact_path=\"weights\")\n",
                "    \n",
                "    print(\"‚úÖ Logged to MLflow\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6 ‚Äî Export ONNX"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "best_model.export(format=\"onnx\", imgsz=640, simplify=True, half=True)\n",
                "print(\"‚úÖ ONNX model exported (FP16)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7 ‚Äî Download Weights\n",
                "\n",
                "‚ö†Ô∏è **Download before the session ends!** Use the Output tab (right sidebar)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil\n",
                "\n",
                "os.makedirs(\"/kaggle/working/weights\", exist_ok=True)\n",
                "\n",
                "for fname in [\"best.pt\", \"last.pt\"]:\n",
                "    src = f\"/kaggle/working/runs/shelfwatch/weights/{fname}\"\n",
                "    if os.path.exists(src):\n",
                "        shutil.copy2(src, f\"/kaggle/working/weights/{fname}\")\n",
                "        print(f\"‚úÖ {fname} ({os.path.getsize(src)/1e6:.1f} MB)\")\n",
                "\n",
                "onnx_src = \"/kaggle/working/runs/shelfwatch/weights/best.onnx\"\n",
                "if os.path.exists(onnx_src):\n",
                "    shutil.copy2(onnx_src, \"/kaggle/working/weights/best.onnx\")\n",
                "    print(f\"‚úÖ best.onnx ({os.path.getsize(onnx_src)/1e6:.1f} MB)\")\n",
                "\n",
                "print(\"\\nüì¶ Download from Output tab ‚Üí\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}